# KAD JE NO ONDA OBRNEMO INDEKSE, STAVIO SAM ISPOD
getEvaluationMetrics <- function(cm) {
# levo je kad je YES pozitivna
# desno je kad je NO pozitivna
TP <- cm[2,2] # cm[1,1]
TN <- cm[1,1] # cm[2,2]
FP <- cm[1,2] # cm[2,1]
FN <- cm[2,1] # cm[1,2]
accuracy = sum(diag(cm))/sum(cm) # tacno predvidjene / sve
precision <- TP / (TP + FP)      # tacno predvidjenje pozitivne / sve predvidjene pozitivne (prva kolona ili druga u zavisnosti od pozitivne klase)
recall <- TP / (TP + FN)         # tacno predvidjenje pozitivne / prvi ili drugi red u zavisnosti od pozitivne klase
F1 <- (2 * precision * recall) / (precision + recall)
c(Accuracy = accuracy,
Precision = precision,
Recall = recall,
F1 = F1)
}
eval.tree1 <- getEvaluationMetrics(tree1.cm)
eval.tree1
# poslednji deo cross validacija: kucaj <folds> u cheatsheetu
library(e1071)
library(caret)
numFolds = trainControl(method = "cv", number = 10)
# CV znaci CrossValidation i kazu nam da kreiramo novo stablo u
# 10 iteracija, pa zato number = 10
cpGrid = expand.grid(.cp = seq(from = 0.001, to = 0.05, by = 0.001))
set.seed(1010) # JAKO BITNO PRE KROS VALIDACIJE !
crossvalidation <- train(x = train.data[,-9],
y = train.data$Take407All,
method = "rpart",
control = rpart.control(minsplit = 10), # opciono, default je 20
trControl = numFolds, # numFolds sto smo dobili iznad
tuneGrid = cpGrid) # cpGrid sto smo dobili iznad
crossvalidation
# u konzoli nam ispisuje koja je najbolja vrednost za cp (complexity parameter)
# dobili smo da je to 0.05, to cemo iskoristiti za nase novo drvo
# pa uporediti vrednosti
# mozemo i da nacrtamo grafik za crossvalidation sa funkcijom plot
plot(crossvalidation)
cpValue <- crossvalidation$bestTune$cp
# prune nam smanjuje nase drvo i pravi jednostavniji model
# poenta je da napravimo sto jednostavnije drvo sa sto
# boljim evaluacionim metrikama
# prune prima kao parametre staro drvo i novi cp
# a cp koji smo dobili krosvalidacijom je 0.05
# posle toga samo  napravimo novu predikciju za nase novo stablo
# napravimo novu matricu konfuzije, izracunamo metrike
# i uporedjujemo sa vrednostima prethodnog ili prethodnih stabala
# u ovom slucaju necemo raditi prune, jer je nase drvo vec najjednostavnije
# moguce, zato cemo napraviti novo samo sa drugom vrednoscu complexity parametra
tree2 <- rpart(Take407All ~ .,
data = train.data,
method = "class",
control = rpart.control(cp = cpValue))
# tree2 <- prune(tree1, cp = cpValue)
tree2.pred <- predict(tree2, newdata = test.data, type = "class")
tree2.cm <- table(true = test.data$Take407All, predicted = tree2.pred) # OVO NEMA U CHEATSHEETU
tree2.cm
eval.tree2 <- getEvaluationMetrics(tree2.cm)
eval.tree1
eval.tree2
# sa sledecom linijom koda ispisujemo i uporedjujemo vrednosti na lep nacin
data.frame(rbind(eval.tree1, eval.tree2), row.names = c("prvi","drugi"))
eval.tree1
# sa sledecom linijom koda ispisujemo i uporedjujemo vrednosti na lep nacin
data.frame(rbind(eval.tree1, eval.tree2), row.names = c("prvi","drugi"))
View(cpGrid)
# prvo moramo da ucitamo dataset nakon sto ga stavimo u root folder
data <- read.csv("travel-times.csv", stringsAsFactors = FALSE)
# uvek prvo gledamo strukturu dataseta
str(data)
summary(data)
# sum sabira sve TRUE vrednosti za dati uslov (TRUE = 1, FALSE = 0)
# pa ce nam sum funkcija pokazati koliko ima TRUE vrednsoti
# apply funkcija se koristi da bismo neku funckiju iskoristili (apply-ovali)
# na vise kolona (zato koristimo MARGIN = 2)
# prvi parametar je dataset, drugi je 2 jer gledamo kolone
# (1 je za redove, a c(1,2) je i za redove i kolone)
# a poslednji parametar FUN je funckija koja se koristi za sve te kolone
# posle function(x) smo stavili konkretnu funckiju koju primenjuje za
# svaku kolonu
apply(data, MARGIN = 2, FUN = function(x) sum(is.na(x)))
apply(data, MARGIN = 2, FUN = function(x) sum(x == "-", na.rm = T))
apply(data, MARGIN = 2, FUN = function(x) sum(x == "", na.rm = T))
apply(data, MARGIN = 2, FUN = function(x) sum(x == " ", na.rm = T))
str(data)
# uklanjanje nedostajucih vrednosti
# proveravamo koje od karakter tipova podataka mozemo da pretvorimo
# u factor (kategoricke) varijable
table(data$GoingTo)
table(data$DayOfWeek)
table(data$FuelEconomy)
data$GoingTo[data$GoingTo == "" | data$GoingTo == "-"] <- NA
data$GoingTo[is.na(data$GoingTo)] <- "Work"
data$GoingTo <- as.factor(data$GoingTo)
data$DayOfWeek <- as.factor(data$DayOfWeek)
data$FuelEconomy[data$FuelEconomy == "" | data$FuelEconomy == "-"] <- NA
sum(is.na(data$FuelEconomy)) # svih 19 smo pretvorili u NA vrednosti
data$FuelEconomy <- as.numeric(data$FuelEconomy)
class(data$FuelEconomy) # proveravamo da li smo pretvorili FuelEconomy u numericku
shapiro.test(data$FuelEconomy)
# pokretanjem shapiro testa vidimo da je p-value = 4.149e-08
# nasa p vrednost je manja od 0.05, nema N raspodelu, tako da
# cemo NA vrednosti zameniti medijanom varijable
# koristimo funckiju median koja prima vrednost za koju ce
# izracunati medijanu, a drugi parametar na.rm znaci REMOVE NA VALUES
# odnosno ukloni NA vrednosti, jer sa NA vrednostima dobijamo i za medijanu
# da je NA, sto nam nista ne znaci
medijanaFuelEco <- median(data$FuelEconomy, na.rm = TRUE)
medijanaFuelEco
data$FuelEconomy[is.na(data$FuelEconomy)] <- medijanaFuelEco
# kreiramo novu kolonu Take407All koja ce uzeti vrednost Yes ako zadovolji
# uslov koji smo uneli, a No ako ne zadovolji
# dobicemo char varijablu koju cemo pretvoriti u factor
# nakon toga cemo izbaciti nepotrebne kolone za model
# uvek uklanjamo one koje smo koristili u uslovu za kreiranje
# izlazne varijable, je nam vise nije potrebna,
# a ostale uklanjamo proizvoljno, ako mislimo
# da nam ne treba za nas model ili ako nam neki testovi kazu
# da varijabla nije relevantna za model koji pravimo
# kolone izbacujemo tako sto kazemo da je nekao kolona jednaka NULL
data$Take407All <- ifelse(data$Congestion407 < 0.61
& data$Comments == "", yes = "Yes", no = "No")
data$Take407All <- factor(data$Take407All)
data$Congestion407 <- NULL
data$Comments <- NULL
# pokazuje prvih 6 vrednosti, tail() pokazuje poslednjih 6
head(data$Take407All)
# koliko ih ima
table(data$Take407All)
# procentualno
prop.table(table(data$Take407All))
data$Date <- NULL
# data$DayOfWeek <- NULL
data$StartTime <- NULL
str(data)
# install.packages('caret')
library(caret)
# koji se random, odnosno nasumicno izvrsava svaki put kada ga pokrenemo
# ako setujemo seed na neki odredjeni broj, onda ce proces randomizacije
# uvek biti isti! Stavite isto kao ja da biste dobili isti rezultat.
# create data partition uvek uzima kao parametre novu izlaznu varijablu
# koju smo kreirali, ovu $Take407All, p = 0.8 sto znaci da cemo uzeti
# 80% podataka kao trening set, a 20% kao test set, to je pravilo
# 80/20, paretov princip (ovo vam nije potrebno, samo malo opste kulture)
# a list nam je uvek FALSE, da nam ne vrati kao listu
# posle toga pravimo datasetove train i test od 80% i 20% vrednosti
# celog dataseta, respektivno
set.seed(1010)
indexes <- createDataPartition(data$Take407All, p = 0.8, list = FALSE)
train.data <- data[indexes, ] # svi oni koji se nalaze u tih 80%
test.data <- data[-indexes, ] # svi oni koji se NE nalazed u tih 80%, ostalih 20%
library(rpart)
tree1 <- rpart(Take407All ~ .,
data = train.data,
method = "class")
tree1
library(rpart.plot)
rpart.plot(tree1, extra = 104) # extra 104 pokazuje brojke na odredjen nacin
tree1.pred <- predict(tree1, newdata = test.data, type = "class")
# na glavnoj dijagonali matrice konfuzije nam se nalazi broj tacnih
# predikcija, a van glavne dijagonale broj pogresnih predikcija
tree1.cm <- table(true = test.data$Take407All, predicted = tree1.pred)
tree1.cm
# napisemo funkciju za evaluaciju i odradimo je na cm
# OVO TAKODJE SAMI UCITE DA PISETE!
# ISPOD JE PRIMER KAD JE YES POZITIVNA KLASA
# KAD JE NO ONDA OBRNEMO INDEKSE, STAVIO SAM ISPOD
getEvaluationMetrics <- function(cm) {
# levo je kad je YES pozitivna
# desno je kad je NO pozitivna
TP <- cm[2,2] # cm[1,1]
TN <- cm[1,1] # cm[2,2]
FP <- cm[1,2] # cm[2,1]
FN <- cm[2,1] # cm[1,2]
accuracy = sum(diag(cm))/sum(cm) # tacno predvidjene / sve
precision <- TP / (TP + FP)      # tacno predvidjenje pozitivne / sve predvidjene pozitivne (prva kolona ili druga u zavisnosti od pozitivne klase)
recall <- TP / (TP + FN)         # tacno predvidjenje pozitivne / prvi ili drugi red u zavisnosti od pozitivne klase
F1 <- (2 * precision * recall) / (precision + recall)
c(Accuracy = accuracy,
Precision = precision,
Recall = recall,
F1 = F1)
}
eval.tree1 <- getEvaluationMetrics(tree1.cm)
eval.tree1
# poslednji deo cross validacija: kucaj <folds> u cheatsheetu
library(e1071)
library(caret)
numFolds = trainControl(method = "cv", number = 10)
# CV znaci CrossValidation i kazu nam da kreiramo novo stablo u
# 10 iteracija, pa zato number = 10
cpGrid = expand.grid(.cp = seq(from = 0.001, to = 0.05, by = 0.001))
set.seed(1010) # JAKO BITNO PRE KROS VALIDACIJE !
crossvalidation <- train(x = train.data[,-9],
y = train.data$Take407All,
method = "rpart",
control = rpart.control(minsplit = 10), # opciono, default je 20
trControl = numFolds, # numFolds sto smo dobili iznad
tuneGrid = cpGrid) # cpGrid sto smo dobili iznad
crossvalidation
# u konzoli nam ispisuje koja je najbolja vrednost za cp (complexity parameter)
# dobili smo da je to 0.05, to cemo iskoristiti za nase novo drvo
# pa uporediti vrednosti
# mozemo i da nacrtamo grafik za crossvalidation sa funkcijom plot
plot(crossvalidation)
cpValue <- crossvalidation$bestTune$cp
# prune nam smanjuje nase drvo i pravi jednostavniji model
# poenta je da napravimo sto jednostavnije drvo sa sto
# boljim evaluacionim metrikama
# prune prima kao parametre staro drvo i novi cp
# a cp koji smo dobili krosvalidacijom je 0.05
# posle toga samo  napravimo novu predikciju za nase novo stablo
# napravimo novu matricu konfuzije, izracunamo metrike
# i uporedjujemo sa vrednostima prethodnog ili prethodnih stabala
# u ovom slucaju necemo raditi prune, jer je nase drvo vec najjednostavnije
# moguce, zato cemo napraviti novo samo sa drugom vrednoscu complexity parametra
tree2 <- rpart(Take407All ~ .,
data = train.data,
method = "class",
control = rpart.control(cp = cpValue))
# tree2 <- prune(tree1, cp = cpValue)
tree2.pred <- predict(tree2, newdata = test.data, type = "class")
tree2.cm <- table(true = test.data$Take407All, predicted = tree2.pred) # OVO NEMA U CHEATSHEETU
tree2.cm
eval.tree2 <- getEvaluationMetrics(tree2.cm)
eval.tree1
eval.tree2
# sa sledecom linijom koda ispisujemo i uporedjujemo vrednosti na lep nacin
data.frame(rbind(eval.tree1, eval.tree2), row.names = c("prvi","drugi"))
# kao sto vidimo, nase metrike se nisu promenile
# kao sto vidimo, nase metrike se nisu promenile
# tako da je nas prvi model zapravo bio savrsen
# kao sto vidimo, nase metrike se nisu promenile
# tako da je nas prvi model zapravo bio savrsen
# da su drugacije metrike samo biste ih prokomentarisali
# kao sto vidimo, nase metrike se nisu promenile
# tako da je nas prvi model zapravo bio savrsen
# da su drugacije metrike samo biste ih prokomentarisali
# i rekli koji model je na kraju bolji
# kao sto vidimo, nase metrike se nisu promenile
# tako da je nas prvi model zapravo bio savrsen
# da su drugacije metrike samo biste ih prokomentarisali
# i rekli koji model je na kraju bolji
# kao sto vidimo, nase metrike se nisu promenile
# tako da je nas prvi model zapravo bio savrsen
# da su drugacije metrike samo biste ih prokomentarisali
# i rekli koji model je na kraju bolji
# kao sto vidimo, nase metrike se nisu promenile
# tako da je nas prvi model zapravo bio savrsen
# da su drugacije metrike samo biste ih prokomentarisali
# i rekli koji model je na kraju bolji
# kao sto vidimo, nase metrike se nisu promenile
# tako da je nas prvi model zapravo bio savrsen
# da su drugacije metrike samo biste ih prokomentarisali
# i rekli koji model je na kraju bolji
# kao sto vidimo, nase metrike se nisu promenile
# tako da je nas prvi model zapravo bio savrsen
# da su drugacije metrike samo biste ih prokomentarisali
# i rekli koji model je na kraju bolji
# kao sto vidimo, nase metrike se nisu promenile
# tako da je nas prvi model zapravo bio savrsen
# da su drugacije metrike samo biste ih prokomentarisali
# i rekli koji model je na kraju bolji
# kao sto vidimo, nase metrike se nisu promenile
# tako da je nas prvi model zapravo bio savrsen
# da su drugacije metrike samo biste ih prokomentarisali
# i rekli koji model je na kraju bolji
# kao sto vidimo, nase metrike se nisu promenile
# tako da je nas prvi model zapravo bio savrsen
# da su drugacije metrike samo biste ih prokomentarisali
# i rekli koji model je na kraju bolji
# kao sto vidimo, nase metrike se nisu promenile
# tako da je nas prvi model zapravo bio savrsen
# da su drugacije metrike samo biste ih prokomentarisali
# i rekli koji model je na kraju bolji
# kao sto vidimo, nase metrike se nisu promenile
# tako da je nas prvi model zapravo bio savrsen
# da su drugacije metrike samo biste ih prokomentarisali
# i rekli koji model je na kraju bolji
# kao sto vidimo, nase metrike se nisu promenile
# tako da je nas prvi model zapravo bio savrsen
# da su drugacije metrike samo biste ih prokomentarisali
# i rekli koji model je na kraju bolji
# kao sto vidimo, nase metrike se nisu promenile
# tako da je nas prvi model zapravo bio savrsen
# da su drugacije metrike samo biste ih prokomentarisali
# i rekli koji model je na kraju bolji
# prvo moramo da ucitamo dataset nakon sto ga stavimo u root folder
data <- read.csv("travel-times.csv", stringsAsFactors = FALSE)
rm(data)
# prvo moramo da ucitamo dataset nakon sto ga stavimo u root folder
data<-read.csv("travel-times.csv", stringsAsFactors = FALSE)
# uvek prvo gledamo strukturu dataseta
str(data)
summary(data)
# prvo moramo da ucitamo dataset nakon sto ga stavimo u root folder
data <- read.csv("travel-times.csv", stringsAsFactors = FALSE)
# uvek prvo gledamo strukturu dataseta
str(data)
summary(data)
# sum sabira sve TRUE vrednosti za dati uslov (TRUE = 1, FALSE = 0)
# pa ce nam sum funkcija pokazati koliko ima TRUE vrednsoti
# apply funkcija se koristi da bismo neku funckiju iskoristili (apply-ovali)
# na vise kolona (zato koristimo MARGIN = 2)
# prvi parametar je dataset, drugi je 2 jer gledamo kolone
# (1 je za redove, a c(1,2) je i za redove i kolone)
# a poslednji parametar FUN je funckija koja se koristi za sve te kolone
# posle function(x) smo stavili konkretnu funckiju koju primenjuje za
# svaku kolonu
apply(data, MARGIN = 2, FUN = function(x) sum(is.na(x)))
apply(data, MARGIN = 2, FUN = function(x) sum(x == "-", na.rm = T))
apply(data, MARGIN = 2, FUN = function(x) sum(x == "", na.rm = T))
apply(data, MARGIN = 2, FUN = function(x) sum(x == " ", na.rm = T))
str(data)
# uklanjanje nedostajucih vrednosti
# proveravamo koje od karakter tipova podataka mozemo da pretvorimo
# u factor (kategoricke) varijable
table(data$GoingTo)
table(data$DayOfWeek)
table(data$FuelEconomy)
data$GoingTo[data$GoingTo == "" | data$GoingTo == "-"] <- NA
View(data)
View(data)
View(data)
tree1.pred <- predict(tree1, newdata = test.data, type = "class")
# prvo moramo da ucitamo dataset nakon sto ga stavimo u root folder
data <- read.csv("travel-times.csv", stringsAsFactors = FALSE)
# uvek prvo gledamo strukturu dataseta
str(data)
summary(data)
# sum sabira sve TRUE vrednosti za dati uslov (TRUE = 1, FALSE = 0)
# pa ce nam sum funkcija pokazati koliko ima TRUE vrednsoti
# apply funkcija se koristi da bismo neku funckiju iskoristili (apply-ovali)
# na vise kolona (zato koristimo MARGIN = 2)
# prvi parametar je dataset, drugi je 2 jer gledamo kolone
# (1 je za redove, a c(1,2) je i za redove i kolone)
# a poslednji parametar FUN je funckija koja se koristi za sve te kolone
# posle function(x) smo stavili konkretnu funckiju koju primenjuje za
# svaku kolonu
apply(data, MARGIN = 2, FUN = function(x) sum(is.na(x)))
apply(data, MARGIN = 2, FUN = function(x) sum(x == "-", na.rm = T))
apply(data, MARGIN = 2, FUN = function(x) sum(x == "", na.rm = T))
apply(data, MARGIN = 2, FUN = function(x) sum(x == " ", na.rm = T))
str(data)
# uklanjanje nedostajucih vrednosti
# proveravamo koje od karakter tipova podataka mozemo da pretvorimo
# u factor (kategoricke) varijable
table(data$GoingTo)
table(data$DayOfWeek)
table(data$FuelEconomy)
data$GoingTo[data$GoingTo == "" | data$GoingTo == "-"] <- "Work"
data$GoingTo <- as.factor(data$GoingTo)
data$DayOfWeek <- as.factor(data$DayOfWeek)
data$FuelEconomy[data$FuelEconomy == "" | data$FuelEconomy == "-"] <- NA
sum(is.na(data$FuelEconomy)) # svih 19 smo pretvorili u NA vrednosti
data$FuelEconomy <- as.numeric(data$FuelEconomy)
class(data$FuelEconomy) # proveravamo da li smo pretvorili FuelEconomy u numericku
shapiro.test(data$FuelEconomy)
# pokretanjem shapiro testa vidimo da je p-value = 4.149e-08
# nasa p vrednost je manja od 0.05, nema N raspodelu, tako da
# cemo NA vrednosti zameniti medijanom varijable
# koristimo funckiju median koja prima vrednost za koju ce
# izracunati medijanu, a drugi parametar na.rm znaci REMOVE NA VALUES
# odnosno ukloni NA vrednosti, jer sa NA vrednostima dobijamo i za medijanu
# da je NA, sto nam nista ne znaci
medijanaFuelEco <- median(data$FuelEconomy, na.rm = TRUE)
medijanaFuelEco
data$FuelEconomy[is.na(data$FuelEconomy)] <- medijanaFuelEco
# kreiramo novu kolonu Take407All koja ce uzeti vrednost Yes ako zadovolji
# uslov koji smo uneli, a No ako ne zadovolji
# dobicemo char varijablu koju cemo pretvoriti u factor
# nakon toga cemo izbaciti nepotrebne kolone za model
# uvek uklanjamo one koje smo koristili u uslovu za kreiranje
# izlazne varijable, je nam vise nije potrebna,
# a ostale uklanjamo proizvoljno, ako mislimo
# da nam ne treba za nas model ili ako nam neki testovi kazu
# da varijabla nije relevantna za model koji pravimo
# kolone izbacujemo tako sto kazemo da je nekao kolona jednaka NULL
data$Take407All <- ifelse(data$Congestion407 < 0.61
& data$Comments == "", yes = "Yes", no = "No")
data$Take407All <- factor(data$Take407All)
data$Congestion407 <- NULL
data$Comments <- NULL
# pokazuje prvih 6 vrednosti, tail() pokazuje poslednjih 6
head(data$Take407All)
# koliko ih ima
table(data$Take407All)
# procentualno
prop.table(table(data$Take407All))
data$Date <- NULL
# data$DayOfWeek <- NULL
data$StartTime <- NULL
str(data)
# install.packages('caret')
library(caret)
# koji se random, odnosno nasumicno izvrsava svaki put kada ga pokrenemo
# ako setujemo seed na neki odredjeni broj, onda ce proces randomizacije
# uvek biti isti! Stavite isto kao ja da biste dobili isti rezultat.
# create data partition uvek uzima kao parametre novu izlaznu varijablu
# koju smo kreirali, ovu $Take407All, p = 0.8 sto znaci da cemo uzeti
# 80% podataka kao trening set, a 20% kao test set, to je pravilo
# 80/20, pareto princip (ovo vam nije potrebno, samo malo opste kulture)
# a list nam je uvek FALSE, da nam ne vrati kao listu
# posle toga pravimo datasetove train i test od 80% i 20% vrednosti
# celog dataseta, respektivno
set.seed(1010)
indexes <- createDataPartition(data$Take407All, p = 0.8, list = FALSE)
train.data <- data[indexes, ] # svi oni koji se nalaze u tih 80%
test.data <- data[-indexes, ] # svi oni koji se NE nalazed u tih 80%, ostalih 20%
library(rpart)
tree1 <- rpart(Take407All ~ .,
data = train.data,
method = "class")
tree1
library(rpart.plot)
rpart.plot(tree1, extra = 104) # extra 104 pokazuje brojke na odredjen nacin
tree1.pred <- predict(tree1, newdata = test.data, type = "class")
# na glavnoj dijagonali matrice konfuzije nam se nalazi broj tacnih
# predikcija, a van glavne dijagonale broj pogresnih predikcija
tree1.cm <- table(true = test.data$Take407All, predicted = tree1.pred)
tree1.cm
# napisemo funkciju za evaluaciju i odradimo je na cm
# OVO TAKODJE SAMI UCITE DA PISETE!
# ISPOD JE PRIMER KAD JE YES POZITIVNA KLASA
# KAD JE NO ONDA OBRNEMO INDEKSE, STAVIO SAM ISPOD
getEvaluationMetrics <- function(cm) {
# levo je kad je YES pozitivna
# desno je kad je NO pozitivna
TP <- cm[2,2] # cm[1,1]
TN <- cm[1,1] # cm[2,2]
FP <- cm[1,2] # cm[2,1]
FN <- cm[2,1] # cm[1,2]
accuracy = sum(diag(cm)) / sum(cm) # tacno predvidjene / sve
precision <- TP / (TP + FP)      # tacno predvidjenje pozitivne / sve predvidjene pozitivne (prva kolona ili druga u zavisnosti od pozitivne klase)
recall <- TP / (TP + FN)         # tacno predvidjenje pozitivne / prvi ili drugi red u zavisnosti od pozitivne klase
F1 <- (2 * precision * recall) / (precision + recall)
c(Accuracy = accuracy,
Precision = precision,
Recall = recall,
F1 = F1)
}
eval.tree1 <- getEvaluationMetrics(tree1.cm)
eval.tree1
# poslednji deo cross validacija: kucaj <folds> u cheatsheetu
library(e1071)
library(caret)
numFolds = trainControl(method = "cv", number = 10)
# CV znaci CrossValidation i kazu nam da kreiramo novo stablo u
# 10 iteracija, pa zato number = 10
cpGrid = expand.grid(.cp = seq(from = 0.001, to = 0.05, by = 0.001))
set.seed(1010) # JAKO BITNO PRE KROS VALIDACIJE !
crossvalidation <- train(x = train.data[,-9],
y = train.data$Take407All,
method = "rpart",
control = rpart.control(minsplit = 10), # opciono, default je 20
trControl = numFolds, # numFolds sto smo dobili iznad
tuneGrid = cpGrid) # cpGrid sto smo dobili iznad
crossvalidation
crossvalidation <- train(x = train.data[,-10],
y = train.data$Take407All,
method = "rpart",
control = rpart.control(minsplit = 10), # opciono, default je 20
trControl = numFolds, # numFolds sto smo dobili iznad
tuneGrid = cpGrid) # cpGrid sto smo dobili iznad
crossvalidation
# poenta je da napravimo sto jednostavnije drvo sa sto
# boljim evaluacionim metrikama
# prune prima kao parametre staro drvo i novi cp
# a cp koji smo dobili krosvalidacijom je 0.05
# posle toga samo  napravimo novu predikciju za nase novo stablo
# napravimo novu matricu konfuzije, izracunamo metrike
# i uporedjujemo sa vrednostima prethodnog ili prethodnih stabala
# u ovom slucaju necemo raditi prune, jer je nase drvo vec najjednostavnije
# moguce, zato cemo napraviti novo samo sa drugom vrednoscu complexity parametra
# tree2 <- prune(tree1, cp = cpValue)
tree2 <- rpart(Take407All ~ .,
data = train.data,
method = "class",
control = rpart.control(cp = cpValue))
tree2.pred <- predict(tree2, newdata = test.data, type = "class")
tree2.cm <- table(true = test.data$Take407All, predicted = tree2.pred) # OVO NEMA U CHEATSHEETU
# DRVO ODLUCIVANJA JE TIP ALGORITMA KOJI RADI SA SVIM VARIJABLAMA !
# prvo moramo da ucitamo dataset nakon sto ga stavimo u root folder
data <- read.csv("travel-times.csv", stringsAsFactors = FALSE)
# gledamo strukturu dataseta
str(data)
summary(data)
# prima dataset, MARGIN = 2 znaci da se izvrsava nad kolonama i FUN je koja funkcija
apply(data, MARGIN = 2, FUN = function(x) sum(is.na(x)))
apply(data, MARGIN = 2, FUN = function(x) sum(x == "-", na.rm = T))
apply(data, MARGIN = 2, FUN = function(x) sum(x == "", na.rm = T))
apply(data, MARGIN = 2, FUN = function(x) sum(x == " ", na.rm = T))
# nijedna varijabla nema NA vrednosti
# varijable FuelEconomy, GoingTo i Comments imaju prazne stringove
# i varijablama FuelEco i GoingTo cemo te stringove zameniti NA vrednostima
# varijablu Comments, zbog prevelikog broja nedostajucih
# vrednosti treba ukloniti jer je irelevantna za nas model
# ostace privremeno radi potrebe za neki od narednih koraka
str(data)
# uklanjanje nedostajucih vrednosti
# proveravamo koje od karakter tipova podataka mozemo da pretvorimo
# u factor (kategoricke) varijable
table(data$GoingTo)
table(data$DayOfWeek)
table(data$FuelEconomy)
# mozemo i length unique da koristimo da bismo videli koliko
# razlicitih vrednosti ima neka varijabla
length(unique(data$GoingTo))
length(unique(data$DayOfWeek))
length(unique(data$Date))
length(unique(data$StartTime))
